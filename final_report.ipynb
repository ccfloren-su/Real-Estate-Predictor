{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652ab777",
   "metadata": {},
   "source": [
    "# Predicting a Range of Offer Prices for Property Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d13fc",
   "metadata": {},
   "source": [
    "## Team Name: JXCKJ\n",
    "Haowen (Jason) Xiong: **haowenxiong**\n",
    "\n",
    "Xiaoyan Qiu: **qxyanbb**\n",
    "\n",
    "Caribel Florentino: **ccfloren-su**\n",
    "\n",
    "Katherine Shapiro: **katieshapiro1**\n",
    "\n",
    "Joyce Lin (POC): **jlin119**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c6e19a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470614e",
   "metadata": {},
   "source": [
    "The aim of this project is to create a machine learning model that predicts residential real estate prices based on property and location characterisitcs. The goal is to help both buyers and sellers understand a realistic price for a home. \n",
    "\n",
    "Our primary stakeholders are real estate agencies who represent both buyers and sellers of residential properties. Purchasing real estate represents a significant economic event for buyers and sellers alike. Therefore, it is important for both buyers and sellers to have an understanding a realistic price based on various factors. Real estate agencies face the challenge of guiding sellers determining a listing pirce and aiding buyers in determing an offer. Currently, these decisions are primairly based on subjective opinions. With the economic significance for buuyers and sellers, it is important for real estate agents to have a prediction that accurately represents the economic value of properties helping their clients reach their goals.\n",
    "\n",
    "Our solution utilizes georgraphical and and property characteristics to predict residential prices. Our model results have a mean absolute error of $256.512.74 indicating that our model can predict house prices within a $250,000 range. While this model doesn't factor in economic data--a big driver of real estate prices--it reveals important features that real estate agencies can use when predicting prices. This model is an incremental step toward aiding real estate egencies with data-driven insights that can enhance decison making resulting in better market-aligned prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763e868",
   "metadata": {},
   "source": [
    "## Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2529b4c9",
   "metadata": {},
   "source": [
    "Recent studies on real estate price prediction have utilized various machine learning algorithms to improve valuation accuracy. These machine learning algorithms include least squares support vector regression, classification and regression tree, general regression neural networks, and backpropagation neural networks, to forecast real estate prices[^1]. Among these, least squares support vector regression has been found to outperform the other models in terms of predictive accuracy[^2]. Traditional real estate valuation models have historically relied on hedonic regression to estimate property values, but recent approaches have shifted towards machine learning techniques such K-Nearest Neighbors, Decision Tree Regression, Artificial Neural Networks, and Support Vector Machines [^3]. The most predictive factors were location and home characteristics, for example, area, square space, and number of rooms. Notably, Regression Trees and Artificial Neural Networks have demonstrated strong performance, achieving the lowest mean absolute error and the highest overall accuracy in certain studies [^4]. \n",
    "\n",
    "However, despite the successes of these machine learning models, several limitations remain. As Stang et al. (2022) highlight, there is no one-size-fits-all approach in machine learning, and models often struggle to generalize across different geographic regions. Additionally, missing or incomplete data presents a significant challenge, as real estate datasets frequently contain null values due to inconsistent data collection or limited publicly available records. These gaps can reduce model performance, requiring imputation techniques or additional preprocessing to maintain accuracy. While machine learning continues to enhance real estate valuation, addressing these limitations is crucial for ensuring models perform well across diverse real estate markets.\n",
    "\n",
    "Based on these current methods, we decided to use an XGBoost Model. Since regression trees provided historically provided strong results, we wanted to utilize a stronger tree-based model to achieve better accuracy. Our data contained over 1 million rows with nulls and outliers. In our reasearch, we found the XGBoost handles all of these aspects well [^5]. With these factors in mind and after testing various models, we found XGBoost met our stakeholder needs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1a604",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999ea2c",
   "metadata": {},
   "source": [
    "This study uses two primary datasets—a financial dataset with historical S&P 500 stock market prices and a large dataset of NYC real estate transactions—to investigate patterns in the city's real estate market and how they relate to macroeconomic factors. Additional data, such as 30-year fixed mortgage rates, real GDP, unemployment rates, the Consumer Price Index (CPI), and OECD consumer confidence indexes, were also obtained from the Federal Reserve Economic Data (FRED). These resources offer a comprehensive basis for comprehending the relationship between house prices and more general financial and economic patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a74dc2",
   "metadata": {},
   "source": [
    "1. NYC Real Estate Sales Dataset\n",
    "\n",
    "![NYC Real Estate Sales Dataset](WechatIMG1719.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4f308",
   "metadata": {},
   "source": [
    "The basic dataset, which includes 10 columns and 1,256,143 rows, represents real estate transactions in each of New York City's five boroughs between 2010 and 2024. It was gathered from a trustworthy and often updated source—the NYC Department of Finance Rolling Sales Reports. Property details such neighborhood, building type, location, ZIP code, land and gross square footage, year built, sale price, and sale date are included in each row. Both residential and commercial properties are represented in the statistics.\n",
    "The existence of both numerical and category characteristics is confirmed by a preview of the data. Certain entries were deemed outliers and dealt with during preprocessing, such as those with implausible build years (for example, before 1800) or selling prices of zero. The dataset is ideal for temporal, geographical, and regression-based analysis due to its scale and diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30390986",
   "metadata": {},
   "source": [
    "2. S&P 500 and Economic Indicators Dataset\n",
    "\n",
    "![S&P 500 and Economic Indicators Dataset](/workspaces/student-group-project-jxckj/final-report/WechatIMG1723.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4f596",
   "metadata": {},
   "source": [
    "The daily open, high, low, and close prices of the S&P 500 stock market from 2010 to 2024 are included in the second core dataset. After being extracted from MarketWatch, the 3,522 rows of data were cleaned and saved as sp500_data_cleaned. It is employed to find possible connections between real estate transactions and market movements. Macroeconomic variables from FRED, such as GDP metrics, unemployment rates, and interest rates, were included to this dataset. These extra factors aid in analyzing the ways in which larger economic factors impact NYC real estate prices and transaction volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6206b8e",
   "metadata": {},
   "source": [
    "Histogram of Property Build Years\n",
    "\n",
    "![Histogram of Property Build Years](/workspaces/student-group-project-jxckj/final-report/WechatIMG1720.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbb23f",
   "metadata": {},
   "source": [
    "A histogram of the YEAR_BUILT column from the NYC dataset is displayed in the first graphic. With a significant concentration in the 1960s and 1970s, the majority of the properties in the dataset were constructed between 1900 and 2000. This distribution sheds light on the age and historical background of NYC's housing stock and points to a significant post-war building boom. Before 1800, a few figures show up, suggesting either data input mistakes or heritage properties. Cleaning took care of these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ff011",
   "metadata": {},
   "source": [
    "Filtered Histogram of Sale Prices (< $4M)\n",
    "![Filtered Histogram of Sale Prices (< $4M)](/workspaces/student-group-project-jxckj/final-report/WechatIMG1721.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7b358",
   "metadata": {},
   "source": [
    "The distribution of selling prices, omitting extreme outliers over $4 million, is depicted in the second plot. The bulk of purchases fall below $1 million, with a sharp decline as prices climb, as this filtered image makes clear. In housing markets, when a few high-value homes have a disproportionate impact on the total statistics, the distribution is typically skewed to the right. In order to ensure that analyses represent realistic dwelling segments, this histogram is essential for getting the data ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ee148",
   "metadata": {},
   "source": [
    "Monthly Average Close Price (S&P 500) & Monthly Average Property Sale Price\n",
    "![Monthly Average Close Price (S&P 500) & Monthly Average Property Sale Price](/workspaces/student-group-project-jxckj/final-report/WechatIMG1722.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c86e1",
   "metadata": {},
   "source": [
    "The average monthly closing price of the S&P 500 index, totaled across all years, is displayed in this line graphic. It shows a distinct upward trend in market performance throughout the course of the year, with the last quarter showing particularly impressive success. The housing sector's investment behavior and risk appetite can be better understood in light of these periodic financial trends.\n",
    "The average monthly home selling price for each year is shown in the final graphic. With noticeable peaks in June and December, the pattern points to cyclical activity. Seasonal patterns in real estate, such year-end closings and spring/summer buying spikes, could be reflected in this. There is visual proof of a possible lag or lead link between financial markets and real estate values when comparing this to the S&P 500 line chart above. This relationship may be investigated further using statistical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143940fa",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94499102",
   "metadata": {},
   "source": [
    "Using public transaction data from 2010 to 2024, we created a machine learning pipeline to evaluate and forecast real estate sale prices in New York City. To lessen skewness and enhance model performance, we log-transformed the sale price of homes, which was our goal variable. The raw datasets were gathered over several years and for each of the following boroughs: Staten Island, Brooklyn, Manhattan, Queens, and the Bronx. To identify the relevant header row, each dataset has to be manually parsed. After that, we cleaned up numeric fields like land square footage, gross area, and sale price, standardized column names, and eliminated nulls and unnecessary columns.\n",
    "\n",
    "We combined this property data with a geocoded address dataset that included latitude and longitude values in order to provide location information. We successfully combined cleansed addresses and ZIP codes by standardizing address formats to increase matching accuracy. Next, we included a categorical location-based feature called grid, assigning each attribute to one of 100 spatial grid cells (a 10×10 grid based on latitude and longitude ranges). We constructed factors such floor space ratio (GROSS_SQUARE_FEET / LAND_SQUARE_FEET), price per square foot (SALE_PRICE / GROSS_SQUARE_FEET), and retrieved year, month, and day from the sale date in addition to geographic characteristics.\n",
    "\n",
    "We used both categorical and numerical predictors for feature selection. Numerical variables were standardized, while categorical information, such building class category, were one-hot encoded. To lessen the impact of outliers and normalize distributions, the numerical features—LAND_SQUARE_FEET, PRICE/SQFT, and FAR—were log-transformed using log1p. Features such as CATEGORY, LAND_SQUARE_FEET, FAR, PRICE/SQFT, YEAR_BUILT, SALE_YEAR, and grid were included in our final dataset.\n",
    "\n",
    "Because of its robustness and interpretability, we first tried Random Forest Regression; nevertheless, the model's ability to capture variation at the high end of selling prices was limited. XGBoost, which is well-suited to handle skewed tabular data and outliers through boosting, was employed in our final and best-performing model. The XGBoost model was set up with 200 estimators, a maximum depth of 5, and a learning rate of 0.05. The log-transformed sale price was used for model training after the data was divided into training and test sets (80/20). To reliably preprocess numerical and categorical information inside a pipeline, the model pipeline used a ColumnTransformer.\n",
    "\n",
    "We made a number of modeling decisions along the process. A poor signal and redundancy with other location information, such grid, led to the exclusion of some features, including BOROUGH, from the final run. Log scaling and latitude and longitude-based grid encoding greatly increased the stability of the model. The finished pipeline offered plausible forecasts and insight into the structural and geographical determinants of NYC real estate values, even if certain residuals were still high, particularly for premium homes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6e67f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe818262",
   "metadata": {},
   "source": [
    "To predict real estate selling prices in New York City, we trained several models with different feature sets and evaluated their performance using regression and classification metrics. Our primary model was the XGBoost regressor, chosen because of its ability to handle skewed tabular data containing outliers. After log-transforming the target variable (sale price), applying spatial grid coding, and integrating structural and temporal features, the model was trained based on data covering the five boroughs of New York City from 2010 to 2024. The data was divided into training and test sets in an 80/20 ratio.\n",
    "\n",
    "The final R² score for the XGBoost model was 0.663, meaning it explained more than 66% of the variability in selling prices. The average R² for cross-validation was 0.525, indicating that the model has moderate generalization ability on the unseen subset. The Mean Absolute Error (MAE) is $256,513, which is reasonable considering the dataset covers properties ranging in price from under $100,000 to over $10 million. A histogram of the residuals shows that the prediction error is centered on zero and slightly skewed to the right; a scatter plot of predicted versus actual prices shows that most points move along the desirable diagonal, especially among properties selling for less than $2 million.\n",
    "\n",
    "To benchmark performance, we also trained a Random Forest Regressor using the same log-transformed and preprocessed dataset. While Random Forest offered interpretable feature importance and resistance to overfitting, it consistently underperformed compared to XGBoost, especially for higher-end properties. The Random Forest model exhibited lower R² values (~0.51) and a slightly higher MAE, struggling to capture tail behavior in the price distribution. This outcome reaffirmed our decision to use boosting methods for greater sensitivity to residual patterns and rare examples.\n",
    "\n",
    "In a complementary experiment, we modeled the prediction problem as a classification task, categorizing selling prices into three categories, which are low, medium, and high. The model achieves an overall accuracy of 82%, with a weighted F1 score of 0.81, and performs particularly well in the high category (F1 score: 0.86). However, the Medium category is poorly predicted (F1 score: 0.02), which may be due to an imbalance in the categories or an overlap of features between price ranges. The confusion matrix shows misclassification often occurs between the medium and high categories.\n",
    "\n",
    "To further assess the impact of geographic granularity, we compared two regression models:\n",
    "Neighborhood model: based on categorical neighborhood labels\n",
    "Geocode model: based on numerical latitude and longitude coordinates grouped by grid.\n",
    "\n",
    "The Geocod model performed slightly better with an MAE of $872,270 and an RMSE of $12.79 million, while the neighborhood model had an MAE of $886,227 and an RMSE of $12.93 million. While the performance difference is small, the Geocode model provides better spatial resolution and supports fine-grained geographic clustering.\n",
    "\n",
    "To explore this further, we performed K-means clustering based on latitude, longitude, and selling price, dividing properties into 5 spatial clusters. These clusters were visually aligned with borough boundaries and economic zones, highlighting the fact that selling prices reflect not only structural features but also hyperlocalized geographies. For example, properties in southern Staten Island cluster together, while central Manhattan forms its high-priced cluster.\n",
    "\n",
    "XGBoost's feature importance metric shows that neighborhoods are by far the most influential predictor, contributing about 87% of the total importance. Other features, such as ZIP codes, grid, building types, and engineering ratios, such as price per square foot, also made significant contributions. This highlights the dominant role of spatial and categorical variables relative to raw numerical variables in the NYC real estate environment.\n",
    "\n",
    "Comparing monthly average selling prices to the monthly trend of the S&P 500 Index, a seasonal pattern emerges. Real estate prices peak in the spring and early summer, while stock market performance tends to rise in the fourth quarter. These consistent trends suggest lagged macroeconomic relationships that can be explored in future research using time series modeling or Granger causality tests. The inclusion of variables such as the consumer price index, mortgage rates, and consumer sentiment in the exploratory charts provides a macroeconomic perspective for interpreting these results.\n",
    "\n",
    "Prototype: Real Estate Price Prediction Tool\n",
    "\n",
    "To demonstrate the practical utility of our model, we developed a prototype function, predict_sale_price(), which allows users to input property characteristics and receive an estimated sale price. This tool takes parameters such as neighborhood, building class, square footage, lot size, ZIP code, year built, and spatial grid cell to generate predictions using the trained XGBoost model.\n",
    "\n",
    "For example, when a user inputs a one-family dwelling located in Midwood, Brooklyn, with 2,500 square feet of interior space, 3,000 square feet of land, built in 1950, and located in ZIP code 11230 within Grid 5, the model predicts an estimated sale price of $1,279,249.\n",
    "\n",
    "Prototype results(in final_model.ipynb):\n",
    "\n",
    "Predicted Sale Price in Midwood (01 One Family Dwellings)\n",
    "\n",
    "Size: 2,500 sqft | Land: 3,000 sqft | Year Built: 1950 | ZIP: 11230 | Grid: 5\n",
    "\n",
    "Estimated Sale Price: $1,279,249\n",
    "\n",
    "This prototype can be expanded into a user-facing web application that allows realtors, buyers, and analysts to explore what-if scenarios and assess market positioning for specific properties. The structured interface also makes it possible to integrate with geospatial maps and additional macroeconomic filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a757f",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc9deb",
   "metadata": {},
   "source": [
    "Our primary goal was to develop a predictive model that would be able to estimate the actual range of asking prices for residential real estate in New York City, while helping stakeholders such as, buyers, sellers, real estate professionals, and economic analysts, to better understand the key factors that drive those prices. To that end, we believe we achieved most of our goals, but not all.\n",
    "\n",
    "We successfully constructed multiple models and evaluated them thoroughly. The final XGBoost model had a test R² score of 0.663 and a mean absolute error of $256,513. Considering the diversity and unpredictability of New York City real estate, this is quite impressive. The model captures patterns across a wide range of price points and provides insight into the importance of spatial, structural, and temporal variables. XGBoost provides more stable and reliable estimates than our previous Random Forest model, which performed poorly, especially in the high-price tails. The Geocode model with lattice-based spatial coding further improves spatial sensitivity and outperforms the simpler neighborhood-based model, validating our view that location granularity is crucial in price prediction.\n",
    "\n",
    "We also constructed a prototype function that allows users to input property features and obtain predicted selling prices. This was critical to achieving our goal of making the results actionable and easy to understand. However, the prototype is still limited in terms of interface and functionality; it is not yet a full-fledged web application and requires further development to achieve wider usability.\n",
    "\n",
    "Despite these successes, we still have some shortcomings. Most notably, our model still struggles with extremely high-priced properties and provides large residuals for certain outliers. While our use of logarithmic transformations helps to reduce skewness, luxury properties often rely on features that do not exist in public datasets, such as interior finishes, view quality, or custom construction. In addition, our attempts to categorize prices into “low,” “medium,” and “high” ranges exposed the inadequacy of the “medium” category. The results exposed deficiencies in the “Medium” category, suggesting that these features either do not clearly differentiate between the categories, or that the category balance needs to be more finely tuned.\n",
    "\n",
    "Significant progress was made in meeting stakeholder needs, but areas for future improvement were identified. For buyers and sellers, the model provides practical estimates of market value, especially when used in conjunction with neighborhood or spatial screening conditions. For real estate professionals, the feature importance results help validate brokers' intuition that both, location comes first. For economic analysts, our integration of macroeconomic indicators, the SP500 Index, the Consumer Price Index, and interest rates, provides valuable background information for time trends.\n",
    "\n",
    "However, we recognize that our tool does not yet fully support policymakers or urban planners, who may require greater interpretability, equity audits, or integration with housing policy datasets. It also does not directly account for eviction trends or zoning changes, which are key factors affecting long-term affordability and equity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23067aa0",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d48dde",
   "metadata": {},
   "source": [
    "We faced many limitations in our developing our model. The limitations impacted the features we were able to incorporate into our final model. Our data had a lot of features that we felt would be important in predicting prices (such as bedrooms and bathrooms), but aren't incorporated into our model. We originally set out to incorporate these features into our model, but we were getting poor results. For this reason, the property characteristics incorporated in the model aren't comprehensive of various houses. This fails to fully meet our stakeholders needs becuase it is important for buyers to determine the price they have to pay when they tell real estate agents how many bedrooms and bathrooms they are looking for. Without these variables, our model limits usability.\n",
    "\n",
    "In addition, going into this project, one of our goals was to incorporate economic features as they impact mortgage rates and mortgage rates determine house affordability. However, we struggled to get a basic model that worked well. With these struggles, we ran out of time to add these additional features. This fails to fully meet our stakeholders needs because economic factors heavily impact when it is a good time to buy or sell a house. \n",
    "\n",
    "As we got closer to the due date and still didn't have a good model, we narrowed our model data to residential properties. When we began this project, we had hoped to incorporate commerical properties as well. Doing so provided our model with much better predictive capability. While we wuld have like to incorporate commerical buildings to be used for real estate agents who sell to both companies and individuals, our model satisfies the stakholders needs of predicting residential properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19ad15",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f901b",
   "metadata": {},
   "source": [
    "The future work that we would like to do to improve our model is incorporate the economic and propety characteristcs that we were unable to incorporate. While doing this, we would like to maintain our R^2 score of 0.66 or improve it even more. In addition, we would like to introduce commercial properties by either creating a separate model using the same characteristics or retaining the model on all of the data we have. \n",
    "\n",
    "Aside from incorporating additional features in our model to create better predictions, we would like to evaluate our errors more to determine what is causing our errors and if there is anything we can do about it. From our analysis so far, we noticed that neighborhood is the most important feature with a feature importance greater than 0.8. Based on this, we would like to evaluate errors within neighborhood to determine if one neighborhood is performing worse or better than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c63a38",
   "metadata": {},
   "source": [
    "[^1]: (Pai & Wang, 2020)\n",
    "\n",
    "[^2]: (Pai & Wang, 2020)\n",
    "\n",
    "[^3]: (Baldominos et al., 2018; Kayakuş et al., 2022)\n",
    "\n",
    "[^4]: (Kayakuş et al., 2022; Baldominos et al., 2018)\n",
    "\n",
    "[^5]: (XGBoosting, 2024. XGBoost advantages and disadvantages (pros vs. cons). https://xgboosting.com/xgboost-advantages-and-disadvantages-pros-vs-cons/.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
